<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Controllable End-to-End Video Ad Creation via Multimodal LLMs">
  <meta property="og:title" content="Text-to-Edit" />
  <meta property="og:description" content="Controllable End-to-End Video Ad Creation via Multimodal LLMs" />
  <meta property="og:url" content="" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="Text-to-Edit">
  <meta name="twitter:description" content="Controllable End-to-End Video Ad Creation via Multimodal LLMs">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="">
  <meta name="twitter:card" content="">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Multimodal LLM, End-toEnd Video Creation, Controllable Free-prompt Editing, Denser Slow-fast Strategy">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Text-to-Edit: Controllable End-to-End Video Ad Creation via Multimodal LLMs</title>
  <link rel="icon" type="image/x-icon" href="static/images/video_card.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Text-to-Edit: Controllable End-to-End Video Ad Creation via
              Multimodal LLMs</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Dabing Cheng,</span>
              <span class="author-block">
                Haosen Zhan,</span>
              <span class="author-block">
                Xingchen Zhao,</span>
              <span class="author-block">
                Guisheng Liu,</span>
              <span class="author-block">
                Zemin Li,</span>
              <span class="author-block">
                <div>
                  Jinghui Xie,
              </span>
              <span class="author-block">
                Zhao Song,</span>
              <span class="author-block">
                Weiguo Feng,</span>
              <span class="author-block">
                Bingyue Peng,</span>
            </div>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">ByteDance Inc.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Arxiv PDF link -->
              <span class="link-block">
                <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Supplementary PDF link -->
              <span class="link-block">
                <a href="static/supplementary.zip" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary</span>
                </a>
              </span>

              <!-- Github link
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

              <!-- ArXiv abstract Link
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span> -->
              </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The exponential growth of short-video content has ignited a surge in the necessity for efficient,
              automated solutions to video editing, with challenges arising from the need to understand videos and
              tailor the editing according to user requirements. Addressing this need, we propose an innovative
              end-to-end foundational framework, ultimately actualizing precise control over the final video content
              editing. Leveraging the flexibility and generalizability of Multimodal Large Language Models (MLLMs), we
              defined clear input-output mappings for efficient video creation. To bolster the model's capability in
              processing and comprehending video content, we introduce a strategic combination of a denser frame rate
              and a slow-fast processing technique, significantly enhancing the extraction and understanding of both
              temporal and spatial video information. Furthermore, we introduce a text-to-edit mechanism that allows
              users to achieve desired video outcomes through textual input, thereby enhancing the quality and
              controllability of the edited videos. Through comprehensive experimentation, our method has not only
              showcased significant effectiveness within advertising datasets, but also yields universally applicable
              conclusions on public datasets.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/main_figure.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/first_figure.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/exp1.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/exp2.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->


  <!-- Core contribution -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Core Contribution</h2>
          <div class="content has-text-justified">
            <p>
              &bull; We propose a novel video editing framework with a multimodal LLM that clearly defines input-output
              formats, streamlining production by managing material comprehension and arrangement in one step. To the
              best of our knowledge, this is the first end-to-end MLLM-based video editing framework.
              <br>
              &bull; We introduce an effective approach employing a denser frame rate and a slow-fast processing
              strategy, which significantly enhances the model's ability to extract and understand temporal and spatial
              video information.
              <br>
              &bull; To improve the controllability of the model's output, we develop a text-driven video editing method
              that ensures the final output aligns precisely with user expectations.
              <br>
              &bull; We conduct comprehensive experiments and exploratory analyses, demonstrating that our proposed
              video editing framework can optimally perform advertising short-video editing tasks. Moreover, our
              framework generalizes well to public datasets, achieving applicable results.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper contribution -->

<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3"> <center>Case Studies</center></h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" controls loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/case1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video1">
          <video poster="" id="video1" controls loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/case2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video1">
          <video poster="" id="video1" controls loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/supp_case1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video1">
          <video poster="" id="video1" controls loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/supp_case2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video1">
          <video poster="" id="video1" controls loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/supp_case3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title"> BibTeX</h2>
      <pre><code>@misc{cheng2025texttoeditcontrollableendtoendvideo,
        title={Text-to-Edit: Controllable End-to-End Video Ad Creation via Multimodal LLMs}, 
        author={Dabing Cheng and Haosen Zhan and Xingchen Zhao and Guisheng Liu and Zemin Li and Jinghui Xie and Zhao Song and Weiguo Feng and Bingyue Peng},
        year={2025},
        eprint={2501.05884},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2501.05884}, 
  }</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              And this website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>